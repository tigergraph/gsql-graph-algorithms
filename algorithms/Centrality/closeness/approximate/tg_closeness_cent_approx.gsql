CREATE DISTRIBUTED QUERY tg_closeness_cent_approx (
    SET<STRING> v_type_set, SET<STRING> e_type_set, STRING reverse_e_type, INT top_k=100, INT k = 100,  INT max_hops = 10,  DOUBLE epsilon = 0.1,  BOOL print_results = true, 
    STRING file_path = "",  INT debug = 0,  INT sample_index = 0,  INT max_size = 1000,   BOOL wf = True ) SYNTAX V1 {
      
    /*
    First Author: kcai2TG
    First Commit Date: Jan 4, 2021

    Recent Author: Boyu Jiang
    Recent Commit Date: Mar 14, 2022


    Repository:
        https://github.com/tigergraph/gsql-graph-algorithms/tree/master/algorithms/Centrality

    Maturity:
        Production

    Description: 
        Compute Closeness Centrality for each VERTEX. 
        Use multi-sourse BFS.

    Publications:
        https://db.in.tum.de/~kaufmann/papers/msbfs.pdf

    TigerGraph Documentation:
        https://docs.tigergraph.com/graph-ml/current/centrality-algorithms/closeness-centrality

    Parameters:
        v_type_set:
            vertex types to traverse
        print_results:
            If True, print JSON output
        e_type_set:
            edge types to traverse
        k:
            sample num
        epsilon:
            error parameter
        debug:
            debug flag -- 0
        reverse_e_type:
            reverse edge type in directed graph, in undirected graph set reverse_e_type=e_type_set
        max_hops:
            max BFS explore steps ,look only this far from each vertex
        file_path:
            file to write CSV output to
        top_k:
            report only this many top scores
        sample_index:
            random sample group
        max_size:
            max size of connected components using exact closeness algorithm
        wf:
            If True, enable Wasserman and Faust normalization factor for multi-component graphs
    */
    
    TYPEDEF TUPLE<VERTEX Vertex_ID, FLOAT score> Vertex_Score;
    HeapAccum<Vertex_Score>(top_k, score DESC) @@top_scores_heap;
    MinAccum<INT> @min_cc_id;      # each vertex's tentative component id
    MapAccum<INT,INT> @@cc_size_map;    # component size 
    MapAccum<VERTEX,INT> @@cc_map;   # closeness centrality of each node
    SumAccum<INT> @sum_vid;  # internal id
    SumAccum<INT> @sum_deltav;  # the distance from the pivot
    SumAccum<INT> @@sum_curDist,@@sum_dist;  # the distance of BFS algorithm 
    MaxAccum<VERTEX> @max_pivot;  # the pivot of the node
    SetAccum<VERTEX> @@sample_set;  # sample node set
    OrAccum<BOOL> @or_sampled;  # sample node
    OrAccum<BOOL> @or_visited,@or_visited0;  # visited node in BFS
    SumAccum<INT> @@sum_total_dist;  # the sum distance of the sample node
    SumAccum<INT> @@sum_nonsample;  # the size of non-sample node in the visiting node
    MapAccum<VERTEX,INT> @@cdist_map;  # the shortest distance between the sample node
    AvgAccum @avg_lavg; # LAVG: the average distance from the sample node within the threshold radius
    SumAccum<INT> @sum_hcsum; # HCSUM: the sum distance from the sample node outside the threshold radius
    SumAccum<INT> @sum_sdist; # record the distance when the sample node cannot be decided
    SumAccum<INT> @sum_lnum; # number of nodes within the threshold radius
    SumAccum<INT> @sum_hsum; # HSUM: the sum distance from non sample node outside the threshold radius
    SumAccum<FLOAT> @sum_total_dist; # the sum distance of the nodes
    SumAccum<FLOAT> @sum_closeness; # the closeness centrality
    SumAccum<INT> @@sum_count = 1;#used to set unique ID
    SumAccum<INT> @sum_id; #store the unique ID
    SetAccum<INT> @@a_set; #used to set unique ID
    MapAccum<INT,INT> @@map; #used to set unique ID 
    BitwiseOrAccum @bitwise_or_seen;
    BitwiseOrAccum @bitwise_or_visit; 
    BitwiseOrAccum @bitwise_or_visit_next; #use bitwise instead of setAccum
    SumAccum<INT> @@sum_curr_dist; #current distance
    SumAccum<INT> @sum_res; #Result, sum of distance
    SumAccum<INT> @sum_size; #get graph size
    FILE f(file_path);
    INT batch_num;
    INT num_vert,partition,i;
    INT vnode_size;
    datetime t1,t2;
    FLOAT eps = 0.00001;
	
    Start = {v_type_set};
    LOG(debug > 0,"query start",Start.size());

    # Total number of nodes
    num_vert = Start.size();

    # Initialize: Label each vertex with its own internal ID
    comp = SELECT x 
        FROM Start:x
        POST-ACCUM x.@min_cc_id = getvid(x);

    # Propagate smaller internal IDs until no more ID changes can be DOne
    WHILE (comp.size()>0) DO
        comp = SELECT t 
            FROM comp:s-(e_type_set)-v_type_set:t
            ACCUM t.@min_cc_id += s.@min_cc_id 	// If s has a smaller id than t, copy the id to t
            HAVING t.@min_cc_id != t.@min_cc_id'; 
    END;

    LOG(debug > 0,"find connected components");

    # get components size
    Start = SELECT s 
        FROM Start:s
        POST-ACCUM @@cc_size_map += (s.@min_cc_id->1);

    LOG(debug > 0,"size of connected components",@@cc_size_map.size());

    FOREACH (cc_id,cc_num) IN @@cc_size_map DO				
        IF cc_num > max_size THEN
            # for large components, get estimate closeness centrality for each vertex
            # partition size
            Conn = SELECT s 
                FROM Start:s
                WHERE s.@min_cc_id == cc_id;   

            IF cc_num % k == 0 THEN
                partition = cc_num/k;
            ELSE
                partition = cc_num/k + 1;
            END;
            print partition;
            PRINT cc_num;

            # sampling
            snode = SELECT s 
                FROM Conn:s
                ACCUM s.@sum_vid += getvid(s)
                HAVING s.@sum_vid % partition== sample_index
                LIMIT k;
            i = sample_index;

            WHILE snode.size() < k DO
                i = (i + 1) % partition;
                snode = SELECT s 
                    FROM Conn:s
                    HAVING s.@sum_vid % partition == i
                    LIMIT k;
            END;

            snode = SELECT s 
                FROM snode:s
                ACCUM 
                    s.@or_sampled += True,
                    @@sample_set += s;
            
            LOG(debug > 0, "sampling finished", snode.size());
            PRINT snode.size();		

            # Set all sample node as the starting point
            @@sum_curDist = 0;
            src = SELECT s 
                FROM snode:s
                ACCUM 
                    s.@max_pivot += s,
                    s.@sum_deltav += @@sum_curDist,
                    s.@or_visited0 += True;

            LOG(debug > 0, "initialize pivot query", src.size());

            # BFS: get the pivot of all nodes and its distance from the pivot
            WHILE src.size() > 0 DO
                @@sum_curDist += 1;
                src = SELECT t 
                    FROM src:s-(e_type_set)-v_type_set:t
                    WHERE t.@or_visited0 == False
                    ACCUM t.@max_pivot += s.@max_pivot
                    POST-ACCUM 
                        t.@or_visited0 += True,
                        t.@sum_deltav = @@sum_curDist;
            END;
            LOG(debug > 0, "pivot query finished", @@sum_curDist);

            # get closeness for community which is larger than maxsize
            FOREACH sample_node IN @@sample_set DO

                # set one sample node as starting node
                LOG(debug > 1,"one sample_node begin");

                vnode = {sample_node};
                vnode = SELECT s 
                    FROM vnode:s
                    ACCUM s.@or_visited += True;

                # the pivot of which is the sample node			
                pivot = SELECT s 
                    FROM Conn:s
                    WHERE s.@or_sampled == False AND s.@max_pivot == sample_node;

                # initialize the shortest distance
                @@sum_dist = 0;
                # initialize the sum of the shortest distance from the sample node
                @@sum_total_dist = 0;
                # initialize the map of shortest distance from other sample node
                @@cdist_map.clear();

                WHILE vnode.size() > 0 do
                    @@sum_dist += 1;

                    # initialize the size of non-sample node in the visiting node
                    @@sum_nonsample = 0;

                    # decide whether the sample node is within or outside the threshold radius from the pivot of the visiting node
                    vnode = SELECT t 
                        FROM vnode:s-(e_type_set)-v_type_set:t
                        WHERE t.@or_visited == False
                        POST-ACCUM 
                            t.@or_visited += True,
                            IF t.@or_sampled == True THEN
                                @@cdist_map += (t->@@sum_dist)  # record the distance between the sample node
                            ELSE
                                # the size of non-sample nodes
                                @@sum_nonsample += 1,
                                # the visiting node in L(u)
                                CASE WHEN t.@sum_deltav > epsilon * @@sum_dist / (1 - epsilon) - eps THEN
                                    t.@avg_lavg += @@sum_dist
                                # the visiting node in HC(u)
                                WHEN t.@sum_deltav < epsilon * @@sum_dist /(1 + epsilon) THEN
                                    t.@sum_hcsum += @@sum_dist
                                # if cannot decided, record the distance
                                ELSE
                                    t.@sum_sdist = @@sum_dist
                                END
                            END;

                    # sum distance of the sample node
                    @@sum_total_dist += vnode.size() * @@sum_dist;

                    # decide whether the visiting node is within or outside the threshold radius from the pivot of which is the sample node
                    vnode_size=vnode.size();
                    pivot = SELECT s 
                        FROM pivot:s
                        POST-ACCUM
                            IF s.@sum_deltav > epsilon * @@sum_dist - eps THEN
                                s.@sum_lnum += vnode_size   # the node num within the threshold radius
                            ELSE
                                s.@sum_hsum += @@sum_nonsample * @@sum_dist   # the sum distance of non-sample node outside the threshold radius
                            END;

                END;

                sampleNode = {sample_node};

                # the sum distance of the sample node
                sampleNode = SELECT s 
                FROM sampleNode:s
                ACCUM s.@sum_total_dist += @@sum_total_dist;			

                # calculate the node which has not been decided before
                post = SELECT s 
                    FROM Conn:s
                    WHERE s.@sum_sdist > 0
                    POST-ACCUM
                        IF @@cdist_map.get(s.@max_pivot) * epsilon < s.@sum_deltav + eps THEN
                            s.@avg_lavg += s.@sum_sdist    # within the threshold radius
                        ELSE
                            s.@sum_hcsum += s.@sum_sdist
                        END;

                # clear the BFS visited accumulator and the distance recorded
                Conn = SELECT s 
                    FROM Conn:s
                    POST-ACCUM s.@or_visited = False, s.@sum_sdist = 0;
                    
                LOG(debug > 1,"one sample_node end");

            END;

            LOG(debug > 0, "BFS from sample node finished");
            #END;
            #IF cc_num>maxsize THEN 
            Conn = SELECT s 
                FROM Conn:s
                ACCUM
                    IF s.@or_sampled == False THEN
                    s.@sum_total_dist = s.@avg_lavg * s.@sum_lnum + s.@sum_hcsum + s.@sum_hsum
                    END
                POST-ACCUM 
                    IF s.@sum_total_dist>0 Then
                        IF wf == True THEN
                            s.@sum_closeness = ((cc_num-1) * 1.0 / (num_vert-1)) * ((cc_num-1) * 1.0 /s.@sum_total_dist)
                        ELSE
                            s.@sum_closeness = ((cc_num - 1) * 1.0) / (s.@sum_total_dist * 1.0)
                        END
                    END,

                    IF print_results THEN 
                        @@top_scores_heap += Vertex_Score(s, s.@sum_closeness) 
                    END,

                    IF file_path != "" THEN 
                        f.println(s, s.@sum_closeness) 
                    END;

            # calculate closeness estimation for all nodes
            LOG(debug > 0, "closeness_est end", Start.size());

            #clear the sample set
            @@sample_set.clear();
        END;
    END;

    LOG(debug > 0,"closeness finished");

    all = SELECT s 
        FROM Start:s 
        WHERE @@cc_size_map.get(s.@min_cc_id)<max_size;

    num_vert = all.size();
    batch_num = num_vert/62;

    IF batch_num==0 THEN 
        batch_num=1;
    END;

    #Calculate the sum of distance to other vertex for each vertex
    FOREACH index IN RANGE[0, batch_num-1] DO
        Start = SELECT s 
            FROM all:s
            WHERE getvid(s)%batch_num == index
            POST-ACCUM @@map+=(getvid(s)->0),@@a_set+=getvid(s);

        FOREACH ver IN @@a_set DO 
            @@map+=(ver->@@sum_count); @@sum_count+=1;
        END; #set a unique ID for each vertex, ID from 1-63

        Start = SELECT s 
            FROM Start:s 
            POST-ACCUM s.@sum_id=@@map.get(getvid(s));

        Start = Select s 
            FROM Start:s
            POST-ACCUM s.@bitwise_or_seen=1<<s.@sum_id,s.@bitwise_or_visit=1<<s.@sum_id; # set initial seen and visit

        @@a_set.clear();
        @@map.clear();
        @@sum_count=0;

        WHILE (Start.size() > 0) LIMIT max_hops DO

            @@sum_curr_dist+=1;

            Start = SELECT t FROM Start:s -(reverse_e_type:e)-v_type_set:t
                WHERE s.@bitwise_or_visit&-t.@bitwise_or_seen-1>0 AND s!=t #use -t.@seen-1 to get the trverse of t.@seen
                ACCUM
                    INT c = s.@bitwise_or_visit&-t.@bitwise_or_seen-1,
                    IF c>0 THEN
                        t.@bitwise_or_visit_next+=c,
                        t.@bitwise_or_seen+=c
                    END
                POST-ACCUM
                    t.@bitwise_or_visit=t.@bitwise_or_visit_next,
                    INT r = t.@bitwise_or_visit_next,
                    WHILE r>0 DO 
                        r=r&(r-1),t.@sum_res+=@@sum_curr_dist,t.@sum_size+=1 #count how many 1 in the number, same as setAccum,size()
                    END,
                    t.@bitwise_or_visit_next=0;
        END;

        @@sum_curr_dist=0;

        Start = SELECT s 
            FROM all:s 
            POST-ACCUM
                s.@bitwise_or_seen=0,
                s.@bitwise_or_visit=0;
    END;

    Start = SELECT s 
        FROM all:s
        # Calculate Closeness Centrality for each vertex
        WHERE s.@sum_res>0
        POST-ACCUM 
            IF wf THEN 
                s.@sum_closeness = (s.@sum_size/(num_vert-1))*(s.@sum_size/s.@sum_res) 
            ELSE 
                s.@sum_closeness = s.@sum_size/s.@sum_res 
            END;		

    #output
    Start = SELECT s 
        FROM Start:s
        POST-ACCUM
            IF file_path != "" THEN
                f.println(s,s.@sum_closeness)
            END;

    IF print_results THEN
        PRINT Start[Start.@sum_closeness];
    END;

    LOG(debug > 0,"closeness output finished");
}
