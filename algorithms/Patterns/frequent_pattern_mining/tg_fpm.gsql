CREATE QUERY tg_fpm(STRING unify_vertex_type, STRING item_vertex_type, STRING connect_edge, DOUBLE support, UINT min_length,
UINT max_count = 10000, INT print_limit = -1, STRING file_path = "")  SYNTAX V1 {

    /*
    First Author: <First Author Name>
    First Commit Date:  <First Commit Date>

    Recent Author: <Recent Commit Author Name>
    Recent Commit Date: <Recent Commit Date>


    Repository:
        https://github.com/tigergraph/gsql-graph-algorithms/tree/master/algorithms/Patterns

    Maturity:
        alpha

    Description: 
        The library is currently under construction! Descriptions will be added soon.

        Schema examples: user - (buys) - product
                   user - (visits) - page
                   user - (rates) - product

        Precondition:
        unify_vertex_type has a List<INT> item_list as an attribute (This can be achived by running pre_process query)

    Publications:
        https://www.researchgate.net/publication/2642957_Mining_Algorithms_for_Sequential_Patterns_in_Parallel_Hash_Based_Approach

    TigerGraph Documentation:
        <link>

    Parameters:
        unify_vertex_type:
            aggregate vertex
        item_vertex_type:
            item vertex
        connect_edge:
            undirected edge that connect the two vertices above
        support:
            minimum pattern frequency to be considered in result
        min_length:
            minimum pattern length to be considered in result
        max_count:
            maximum number of patterns returned by the algorithm
        print_limit:
            an integer to limit the length of the query result printed; use -1 for no limit
        file_path:
            file path to write csv output to; use empty string to skip output to file
    */

  TYPEDEF TUPLE<INT pattern_key, INT suffix_key> key_pair;
  TYPEDEF TUPLE<INT pattern_key, DOUBLE frequency, INT length> frequent_pattern_node;
  MapAccum<INT, SumAccum<INT>> @counter_map;
  MapAccum<INT, MaxAccum<key_pair>> @lookup_table_map;
  SetAccum<key_pair> @work_order_set;
  OrAccum<BOOL> @or_is_eligible = TRUE;
  SumAccum<INT> @sum_superset_counter = 0;

  MaxAccum<INT> @@max_sq_length = 0;
  ListAccum<INT> @@HASH_CONST_list;
  MapAccum<INT, ListAccum<INT>> @@pattern_lookup_map, @@new_pattern_lookup_map;
  MapAccum<INT, ListAccum<VERTEX>> @@suffix_map;
  HeapAccum<frequent_pattern_node>(max_count, frequency DESC, length DESC) @@frequent_pattern_heap;
  FILE f(file_path);

  INT min_support = 0;
  INT unify_size = 0;
  INT print_count = 0;
  INT curr_length = 0;

  ##### Initialize #####
  unify = {unify_vertex_type.*};
  unify_size = unify.size();

  unify = SELECT s
          FROM unify:s
          ACCUM
              @@max_sq_length += s.item_list.size();

  @@HASH_CONST_list = tg_initiate_hash_const(@@max_sq_length);
  min_support = CEIL(unify_size*support);

  items = {item_vertex_type.*};

  items = SELECT s
          FROM items:s - (connect_edge) -> unify_vertex_type:t
          ACCUM
              s.@counter_map += (tg_get_hash(getvid(s)) -> 1)
          POST_ACCUM
              s.@lookup_table_map += (tg_get_hash(getvid(s)) -> key_pair(0, getvid(s)));

  ##### Generate sequence of length k + 1 from k #####
  WHILE TRUE DO
      curr_length = curr_length + 1;
      items = SELECT s
              FROM items:s
              ACCUM
                  FOREACH (key, cnt) in s.@counter_map DO
                      IF cnt >= min_support  THEN
                          INT p_key = tg_get_pattern_key(s.@lookup_table_map.get(key)),
                          INT s_key = tg_get_suffix_key(s.@lookup_table_map.get(key)),

                          INT first_element = s_key,
                          IF curr_length > 1 THEN
                              first_element = @@pattern_lookup_map.get(p_key).get(0)
                          END,

                          IF curr_length < min_length THEN
                              @@new_pattern_lookup_map += (key -> tg_concat(@@pattern_lookup_map.get(p_key), s_key))
                          ELSE
                              @@frequent_pattern_heap += frequent_pattern_node(key, cnt*1.0/unify_size, curr_length),
                              @@pattern_lookup_map += (key -> tg_concat(@@pattern_lookup_map.get(p_key), s_key))
                          END,
                          s.@work_order_set += key_pair(key, tg_get_hash_without_first_element(key, first_element, curr_length, @@HASH_CONST_list)),
                          @@suffix_map += (tg_get_hash_without_last_element(key, getvid(s)) -> s)
                      END
                  END
              POST-ACCUM
                  s.@lookup_table_map.clear(),
                  s.@counter_map.clear()
              HAVING s.@work_order_set.size() != 0;

    IF items.size() == 0 or @@frequent_pattern_heap.size() == max_count THEN
        BREAK;
    END;

    IF curr_length < min_length THEN
        @@pattern_lookup_map = @@new_pattern_lookup_map;
        @@new_pattern_lookup_map.clear();
    END;

    ss = SELECT t
         FROM items:s - (connect_edge) -> unify_vertex_type:t
         WHERE t.@or_is_eligible AND t.item_list.size() >= curr_length
         ACCUM
             INT suffix_vid = 0,
             FOREACH wo in s.@work_order_set DO
                 FOREACH suffix_page in @@suffix_map.get(wo.suffix_key) DO
                     suffix_vid = getvid(suffix_page),

                     IF tg_is_subset(@@pattern_lookup_map.get(wo.pattern_key), suffix_vid, t.item_list) THEN
                         suffix_page.@counter_map += (tg_get_hash_concat(wo.pattern_key, suffix_vid) -> 1),
                         suffix_page.@lookup_table_map += (tg_get_hash_concat(wo.pattern_key, suffix_vid)
                         -> key_pair(wo.pattern_key, suffix_vid)),
                         t.@sum_superset_counter += 1
                     END
                 END
             END
         POST_ACCUM
             s.@work_order_set.clear(),
             t.@or_is_eligible = t.@sum_superset_counter != t.@sum_superset_counter';

     @@suffix_map.clear();
  END;

  ##### Output #####
  IF file_path != "" THEN
      f.println("FREQUENCY", "PATTERN_LIST");
  END;

  IF print_limit != 0 OR file_path != "" THEN
      WHILE NOT @@frequent_pattern_heap.size() == 0 DO
          IF (print_limit == -1 or print_limit > 0 and print_count < print_limit) THEN
              PRINT @@frequent_pattern_heap.top().frequency as support,
              tg_to_vertex_list(@@pattern_lookup_map.get(@@frequent_pattern_heap.top().pattern_key)) as pattern;
              print_count = print_count + 1;
          END;

          IF file_path != "" THEN
              f.println(@@frequent_pattern_heap.top().frequency, @@pattern_lookup_map.get(@@frequent_pattern_heap.top().pattern_key));
          END;
          @@frequent_pattern_heap.pop();
      END;
  END;
}
